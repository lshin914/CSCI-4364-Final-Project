{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "from keras import datasets, layers, models # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isaacbilsel/Documents/GW_Projects/ML/CSCI-4364-Final-Project/C-NMC_Leukemia/training_data/fold_0/all\n"
     ]
    }
   ],
   "source": [
    "# Establish filepaths \n",
    "all_0 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_0/all\"\n",
    "all_1 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_1/all\"\n",
    "all_2 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_2/all\"\n",
    "\n",
    "hem_0 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_0/hem\"\n",
    "hem_1 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_1/hem\"\n",
    "hem_2 = os.getcwd() + \"/C-NMC_Leukemia/training_data/fold_2/hem\"\n",
    "print(all_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_image(folder):\n",
    "    image_paths = []\n",
    "    image_fnames = os.listdir(folder) \n",
    "    for img_id in range(len(image_fnames)):\n",
    "        img = os.path.join(folder,image_fnames[img_id])\n",
    "        image_paths.append(img)\n",
    "    \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527\n",
      "3553\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# for i in [all_0,all_1,all_2,hem_0,hem_1,hem_2]:\n",
    "for i in [all_0,hem_0]:   # Start training on just the first folder\n",
    "    paths = get_path_image(i)\n",
    "    train_data.extend(paths)\n",
    "print(len(train_data))\n",
    "\n",
    "# Test data is the last folder for now \n",
    "# (because idk how to parse the csv file to get the test labels)\n",
    "for i in [all_2,hem_2]:   \n",
    "    paths = get_path_image(i)\n",
    "    test_data.extend(paths)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe and add labels\n",
    "# Training Data\n",
    "tr_data = {\"img_data\":train_data,\n",
    "        \"labels\":[np.nan for x in range(len(train_data))]}\n",
    "df_train = pd.DataFrame(tr_data)\n",
    "df_train[\"labels\"][0:2379] = 1 # ALL:  2397 in folder 0, 7272 in all 3 folders\n",
    "df_train[\"labels\"][2379:] = 0 # HEM  1130 in folder 1, 3389 in all 3 folders\n",
    "df_train[\"labels\"] = df_train[\"labels\"].astype(\"int64\")\n",
    "\n",
    "# Test Data\n",
    "ts_data = {\"img_data\":test_data,\n",
    "        \"labels\":[np.nan for x in range(len(test_data))]}\n",
    "df_test = pd.DataFrame(ts_data)\n",
    "df_test[\"labels\"][0:2457] = 1 # ALL:  2457 in folder 0, 7272 in all 3 folders\n",
    "df_test[\"labels\"][2457:] = 0 # HEM  1096 in folder 1, 3389 in all 3 folders\n",
    "df_test[\"labels\"] = df_test[\"labels\"].astype(\"int64\")\n",
    "\n",
    "train_x = np.asarray(df_train[\"img_data\"])\n",
    "train_y = np.asarray(df_train[\"labels\"])\n",
    "test_x = np.asarray(df_test[\"img_data\"])\n",
    "test_y = np.asarray(df_test[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10661 entries, 0 to 10660\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   img_data  10661 non-null  object \n",
      " 1   labels    3509 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 166.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3553 entries, 0 to 3552\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   img_data  3553 non-null   object\n",
      " 1   labels    3553 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(df_train[\"img_data\"][100])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,156,226\n",
      "Trainable params: 20,156,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creat Model Structure\n",
    "For high accuracy, it seems like we need to build on a pretrained CNN\n",
    "The two top solutions on kaggle build on efficientnet and Resnet\n",
    "We could build on VGG, which is another strong option\n",
    "VGG19 extracts important features from the dataset\n",
    "'''\n",
    "\n",
    "pretrained_model = VGG19(weights='imagenet', input_shape = (224, 224, 3), include_top=False, pooling=\"avg\")\n",
    "\n",
    "model = Sequential([\n",
    "    pretrained_model,\n",
    "    # MaxPooling2D((2,2) , strides = 2),\n",
    "    Flatten(),\n",
    "    # BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    Dense(256, activation='softmax'),\n",
    "    Dropout(rate= 0.45, seed= 123),\n",
    "    Dense(2, activation='softmax')])\n",
    "model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='vgg19_input'), name='vgg19_input', description=\"created by layer 'vgg19_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_17'), name='input_17', description=\"created by layer 'input_17'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"vgg19\" (type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"vgg19\" (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f6/mcxlkrd15h37z4kj8l7n7dcw0000gn/T/ipykernel_3655/3547374361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# batch_size = 64 ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, callbacks = [learning_rate_reduction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/isaacbilsel/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"vgg19\" (type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"vgg19\" (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 3, verbose=1,factor=0.6, min_lr=0.000001)\n",
    "\n",
    "history = model.fit(train_x,train_y, batch_size = 64 , epochs = 25 , validation_data = (test_x, test_y), callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
